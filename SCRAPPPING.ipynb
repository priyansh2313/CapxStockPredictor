{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fouTMZ9n8DTv"
      },
      "outputs": [],
      "source": [
        "pip install praw"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FETCHING THE POSTS"
      ],
      "metadata": {
        "id": "6Rd4O0WE8cSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "\n",
        "reddit = praw.Reddit(client_id='dso-2wKoiaavUz1AoA3BCQ',\n",
        "                     client_secret='NkN503DNQF3R5aNrW9ebO_WC1TqEAA',\n",
        "                     user_agent='StockDataScraper v1.0')\n",
        "\n",
        "subreddits = ['stocks', 'investing', 'wallstreetbets', 'stockmarket', 'financialindependence']\n",
        "\n",
        "for subreddit_name in subreddits:\n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "\n",
        "    print(f\"Fetching posts from subreddit: {subreddit_name}\")\n",
        "\n",
        "    top_posts = subreddit.top(limit=500)\n",
        "\n",
        "    for post in top_posts:\n",
        "        print(f\"Title: {post.title}\")\n",
        "        print(f\"Text: {post.selftext}\")\n",
        "        print(f\"Score: {post.score}\")\n",
        "        print(f\"URL: {post.url}\")\n",
        "        print('-' * 80)\n"
      ],
      "metadata": {
        "id": "AXFS5T6K8KqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADDING MORE SUB-REDDITS"
      ],
      "metadata": {
        "id": "wWEkUCkk8fjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subreddits = ['stocks', 'investing', 'StockMarket', 'wallstreetbets', 'finance']\n",
        "\n",
        "all_posts = []\n",
        "\n",
        "for subreddit in subreddits:\n",
        "    print(f\"Fetching posts from r/{subreddit}...\")\n",
        "    posts = reddit.subreddit(subreddit).search('stock', limit=2000)\n",
        "    for post in posts:\n",
        "        all_posts.append({\n",
        "            'Title': post.title,\n",
        "            'Author': post.author.name if post.author else 'N/A',\n",
        "            'Upvotes': post.score,\n",
        "            'Comments': post.num_comments,\n",
        "            'Created': post.created_utc,\n",
        "            'URL': post.url\n",
        "        })\n"
      ],
      "metadata": {
        "id": "UFdxWPav8SQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONVERTING TO DATFRAME AND DOWNLOADING THE CSV FILE"
      ],
      "metadata": {
        "id": "wnxPU-a989HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.DataFrame(all_posts)\n",
        "\n",
        "\n",
        "df.to_csv('reddit_combined_posts.csv', index=False)\n",
        "print(f\"Collected {len(df)} posts across all subreddits.\")\n"
      ],
      "metadata": {
        "id": "wFb7pnY08V2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oB6a9iG8Yqs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}