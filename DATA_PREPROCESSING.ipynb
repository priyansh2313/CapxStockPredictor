{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avb9HcCz9I8X"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('reddit_combined_posts.csv')\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "print(df.info())\n",
        "\n",
        "print(df.isnull().sum())\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "df = df.dropna(subset=['Title'])\n",
        "\n",
        "print(f\"Dataset after cleaning has {len(df)} entries.\")\n"
      ],
      "metadata": {
        "id": "0Isj02kF9dlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "df = pd.read_csv('reddit_combined_posts.csv')\n",
        "\n",
        "df = df.dropna(subset=['Title'])\n",
        "\n",
        "def preprocess_text_spacy(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['Cleaned_Title'] = df['Title'].apply(preprocess_text_spacy)\n",
        "\n",
        "print(df[['Title', 'Cleaned_Title']].head())\n"
      ],
      "metadata": {
        "id": "Slla0Ycz9i9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SENTIMENT ANALYSIS"
      ],
      "metadata": {
        "id": "hroh1yXy9vPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "df['Sentiment_Polarity'] = df['Cleaned_Title'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "print(df[['Cleaned_Title', 'Sentiment_Polarity']].head())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(df['Sentiment_Polarity'], bins=20, edgecolor='k')\n",
        "plt.title('Distribution of Sentiment Polarity')\n",
        "plt.xlabel('Sentiment Polarity')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-OerlrPt9mzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXTRACTING FEATURES RELEVANT TO STOCK MARKET"
      ],
      "metadata": {
        "id": "QEryWog_-pfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Word_Count'] = df['Cleaned_Title'].apply(lambda x: len(x.split()))\n",
        "\n",
        "df['Normalized_Upvotes'] = (df['Upvotes'] - df['Upvotes'].mean()) / df['Upvotes'].std()\n",
        "\n",
        "df['Comment_Upvote_Ratio'] = df['Comments'] / (df['Upvotes'] + 1)\n",
        "\n",
        "print(df[['Cleaned_Title', 'Word_Count', 'Normalized_Upvotes', 'Comment_Upvote_Ratio']].head())\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df[['Sentiment_Polarity', 'Word_Count', 'Normalized_Upvotes', 'Comment_Upvote_Ratio']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7qoJykpQ-nid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADDING LABEL COLUMN"
      ],
      "metadata": {
        "id": "YJtOHAUZ-xPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_labels(row):\n",
        "    if row['Sentiment_Polarity'] > 0.1:\n",
        "        return 1  # Positive\n",
        "    elif row['Sentiment_Polarity'] < -0.1:\n",
        "        return -1  # Negative\n",
        "        return 0  # Neutral\n",
        "\n",
        "df['Label'] = df.apply(create_labels, axis=1)\n",
        "print(\"Label column created successfully!\")\n",
        "print(df[['Title', 'Sentiment_Polarity', 'Label']].head())\n"
      ],
      "metadata": {
        "id": "MlkyF_UF-zrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARING THE MODEL AND GENERATING THE CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "1CkC76wq-70H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "features = ['Sentiment_Polarity', 'Word_Count', 'Normalized_Upvotes', 'Comment_Upvote_Ratio']\n",
        "target = 'Label'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Neutral', 'Positive'], yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "U-OrEuN7_CKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING THE MODEL"
      ],
      "metadata": {
        "id": "p7V9_-R7_GQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(rf_model,open('Stock_model.pkl','wb'))\n",
        "\n",
        "print(\"model successfully saved\")\n",
        "\n"
      ],
      "metadata": {
        "id": "o0KJPV2o_FAl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}